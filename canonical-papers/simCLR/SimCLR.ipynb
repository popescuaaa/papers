{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1821a6e0",
   "metadata": {},
   "source": [
    "### SimCLR\n",
    "\n",
    "A Simple Framework for Contrastive Learning of Visual Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c19c92c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision as tv\n",
    "import torchvision.datasets as tvd\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from typing import Union\n",
    "\n",
    "\n",
    "# Setting device and seed for experiments reproductibility\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d5ca368f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar/train/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 170498071/170498071 [00:08<00:00, 19644378.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar/train/cifar-10-python.tar.gz to ./data/cifar/train\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar/test/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 170498071/170498071 [00:08<00:00, 20205291.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar/test/cifar-10-python.tar.gz to ./data/cifar/test\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])    \n",
    "])\n",
    "\n",
    "train_dataset = tvd.CIFAR10(root=\"./data/cifar/train\", download=True, transform=transform, train=True)\n",
    "test_dataset = tvd.CIFAR10(root=\"./data/cifar/test\", download=True, transform=transform, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2b94210",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ac5a28c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_dl = DataLoader(dataset=train_dataset, shuffle=True, batch_size=batch_size)\n",
    "test_dl = DataLoader(dataset=test_dataset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b652a7",
   "metadata": {},
   "source": [
    "### Basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d41c8763",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3f84bdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "lr = 1e-3\n",
    "momentum = 0.9\n",
    "\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c1ddbe77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.223\n",
      "[2,  2000] loss: 1.638\n",
      "[3,  2000] loss: 1.432\n",
      "[4,  2000] loss: 1.320\n",
      "[5,  2000] loss: 1.233\n",
      "[6,  2000] loss: 1.155\n",
      "[7,  2000] loss: 1.084\n",
      "[8,  2000] loss: 1.034\n",
      "[9,  2000] loss: 0.980\n",
      "[10,  2000] loss: 0.927\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs): \n",
    "    running_loss = 0.0\n",
    "    for idx, data in enumerate(train_dl):\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        if idx % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f\"Epoch:{epoch + 1} Minibatch end: {idx + 1:5d} Loss: {running_loss / 2000:.3f}\")\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a053d917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "PATH = f\"./cifar_net_{epochs}_{lr}_m{momentum}.pth\"\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125c18ce",
   "metadata": {},
   "source": [
    "### Computing accuracy for the basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1502f472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 625 test images: 62.00 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_dl:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the {len(test_dl)} test images: {100 * correct // total:.2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2fd854",
   "metadata": {},
   "source": [
    "### SimCLR learnig procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418cfd12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42170bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7e070f0",
   "metadata": {},
   "source": [
    "### Compare the two training procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903d4431",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
